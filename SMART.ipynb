{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/karl/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/karl/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import re\n",
    "import pandas as pd\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(filepath):\n",
    "    '''\n",
    "    Doc...\n",
    "    '''\n",
    "    obj = []\n",
    "    with open(filepath, 'r') as file:\n",
    "        obj = json.load(file)\n",
    "    return obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train = load_dataset('datasets/DBpedia/smarttask_dbpedia_train.json')\n",
    "train = load_dataset('../smart-dataset/datasets/Wikidata/lcquad2_anstype_wikidata_train.json')\n",
    "test = load_dataset('../smart-dataset/datasets/Wikidata/lcquad2_anstype_wikidata_test_gold.json')\n",
    "# terms = ['who', 'what', 'when', 'where', 'which', 'whom', 'whos', 'why', 'do', 'how', 'is']\n",
    "categories = {'who':'resource', \n",
    "            'what':'resource', \n",
    "            'when':'literal', \n",
    "            'where':'resource',\n",
    "            'which':'literal',\n",
    "            'whom': 'resource',\n",
    "            'whose': 'resource',\n",
    "            'why': 'literal',\n",
    "            'was': 'boolean',\n",
    "            'do':'boolean',\n",
    "            'does': 'boolean',\n",
    "            'is':'boolean',\n",
    "            'did': 'boolean',\n",
    "            'how': 'literal',\n",
    "            'list': 'resource',\n",
    "            'are': 'boolean',\n",
    "            'name': 'resource',\n",
    "            'tell': 'resource',\n",
    "            'were': 'boolean',\n",
    "            'count': 'literal'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorize(question):\n",
    "    '''\n",
    "    Doc...\n",
    "    '''\n",
    "    if type(question) is not str:\n",
    "        return None\n",
    "    question = question.lower()\n",
    "    idxs = {}\n",
    "    for term in categories.keys():\n",
    "        val = re.search(r'\\b({})\\b'.format(term), question)\n",
    "        if val is not None:\n",
    "            idxs[val.start()] =  term\n",
    "\n",
    "    if len(idxs.keys()) == 0:\n",
    "        return None\n",
    "    \n",
    "    return categories[idxs[min(idxs.keys())]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'resource'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorize(\"What does the numbers mean?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7248917867514109\n",
      "225\n",
      "{'id': 19829, 'question': \"Could you summarize Korea's history of this topic?\", 'category': 'resource', 'type': ['aspect of history', 'history of the world']}\n",
      "\n",
      "{'id': 22651, 'question': 'n/a', 'category': 'resource', 'type': ['human settlement']}\n",
      "\n",
      "{'id': 18673, 'question': 'Of the century breaks of the Colm Gilcreest equal less than 9.6?', 'category': 'boolean', 'type': ['boolean']}\n",
      "\n",
      "{'id': 25365, 'question': 'Give me a film character from a fictional universe, such as Marvel comics that starts with a W.', 'category': 'resource', 'type': ['fictional character']}\n",
      "\n",
      "{'id': 21297, 'question': 'Mention the fictional universe described or included in The Matrix.', 'category': 'resource', 'type': ['fictional location', 'setting', 'fictional entity']}\n",
      "\n",
      "{'id': 22857, 'question': 'n/a', 'category': 'resource', 'type': ['community', 'geographic region', 'geographic location', 'artificial geographic entity', 'administrative territorial entity of Guatemala', 'second-level administrative country subdivision', 'municipio']}\n",
      "\n",
      "{'id': 21021, 'question': 'Mention the headquarter location of the Russian Orthodox Church monastery.', 'category': 'resource', 'type': ['institutional complex', 'heritage site', 'religious building', 'place of worship', 'organization']}\n",
      "\n",
      "{'id': 28585, 'question': 'Whats the Brockhaus Enzyklopadie online ID of Chile?', 'category': 'literal', 'type': ['string']}\n",
      "\n",
      "{'id': 19788, 'question': 'Followers', 'category': 'resource', 'type': ['language']}\n",
      "\n",
      "{'id': 13863, 'question': 'This sentence makes no sense.', 'category': 'resource', 'type': ['military unit', 'marine unit']}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "invalid = 0\n",
    "qs = []\n",
    "for doc in train:\n",
    "    question = doc['question']\n",
    "    category = doc['category']\n",
    "    prediction = categorize(question)\n",
    "    if prediction is None:\n",
    "        invalid += 1\n",
    "        qs.append(doc)\n",
    "    if prediction == category:\n",
    "        count += 1\n",
    "\n",
    "print(count/len(train))\n",
    "print(invalid)\n",
    "for q in qs[:10]:\n",
    "    print(q)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_X_y(train, test):\n",
    "    '''\n",
    "    doc...\n",
    "    '''\n",
    "    X_train = []\n",
    "    y_train = []\n",
    "    X_test = []\n",
    "    y_test = []\n",
    "    \n",
    "    for doc in train:\n",
    "        X_train.append(doc['question'])\n",
    "        y_train.append(doc['category'])\n",
    "        \n",
    "    for doc in test:\n",
    "        X_test.append(doc['question'])\n",
    "        y_test.append(doc['category'])\n",
    "\n",
    "    \n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(train_dataset, test_dataset):\n",
    "    \"\"\"Extracts feature vectors from a preprocessed train and test datasets.\n",
    "    \n",
    "    Args:\n",
    "        train_dataset: List of strings, each consisting of the preprocessed email content. \n",
    "        test_dataset: List of strings, each consisting of the preprocessed email content. \n",
    "    \n",
    "    Returns:\n",
    "        \n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "#     vectorizer = TfidfVectorizer(sublinear_tf=True, max_df=0.5)\n",
    "    vectorizer = CountVectorizer()\n",
    "    train_vectors = vectorizer.fit_transform(train_dataset)\n",
    "    \n",
    "    test_vectors = vectorizer.transform(test_dataset)\n",
    "    return train_vectors, test_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = prepare_X_y(train, test)\n",
    "train_vectors, test_vectors = extract_features(X_train, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(X, y):\n",
    "    \"\"\"Trains a classifier on extracted feature vectors.\n",
    "    \n",
    "    Args:\n",
    "        X: Numerical array-like object (2D) representing the instances.\n",
    "        y: Numerical array-like object (1D) representing the labels.\n",
    "    \n",
    "    Returns:\n",
    "        A trained model object capable of predicting over unseen sets of instances.\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    clf = MultinomialNB(alpha=.01)\n",
    "    clf.fit(X, y)\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainMLP(X, y):\n",
    "    \"\"\"Trains a classifier on extracted feature vectors.\n",
    "    \n",
    "    Args:\n",
    "        X: Numerical array-like object (2D) representing the instances.\n",
    "        y: Numerical array-like object (1D) representing the labels.\n",
    "    \n",
    "    Returns:\n",
    "        A trained model object capable of predicting over unseen sets of instances.\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    clf = MLPClassifier(random_state=1, max_iter=300)\n",
    "    clf.fit(X, y)\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = train(train_vectors, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8361408882082695"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = classifier.predict(test_vectors)\n",
    "sum(pred==y_test)/len(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'literal'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9022095821483264"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifierMLP = trainMLP(train_vectors, y_train)\n",
    "pred = classifierMLP.predict(test_vectors)\n",
    "sum(pred==y_test)/len(pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
